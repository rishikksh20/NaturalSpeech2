data:
  data_dir: 'data_dir'
  wav_dir: 'wav_dir'
  # Compute statistics

  f0_mean: 261.04640892167527
  f0_std:  68.26509993190999
  p_min: 64.7767333984375
  p_max: 445.81951904296875
  train_filelist: ""
  valid_filelist: ""
  tts_cleaner_names: ['english_cleaners']

# feature extraction related
audio:
  sample_rate: 16000      # sampling frequency
  fmax: 8000.0       # maximum frequency
  fmin: 0.0       # minimum frequency
  n_mels: 80     # number of mel basis
  n_fft: 1024    # number of fft points
  hop_length: 200   # number of shift points
  win_length: 1024 # window length
  num_mels : 80
  min_level_db : -100
  ref_level_db : 20
  bits : 9                            # bit depth of signal
  mu_law : True                       # Recommended to suppress noise if using raw bits in hp.voc_mode below
  peak_norm : False                   # Normalise to the peak of each wav file



# network architecture related
model:
  embed_dim: 0
  adim: 512
  aheads: 8
  elayers: 6
  eunits: 2048
  encoder_dropout: 0.2
  positionwise_layer_type: "conv1d" # linear
  positionwise_conv_kernel_size: 9 # 1

  ddim: 256
  dlayers: 4
  dunits: 1024


  reduction_factor: 1
  loss_type : "L1"

  # minibatch related
  batch_sort_key: input # shuffle or input or output
  batch_bins: 2549760    # 12 * (870 * 80 + 180 * 35)
                        # batch_size * (max_out * dim_out + max_in * dim_in)
                        # resuling in 11 ~ 66 samples (avg 15 samples) in batch (809 batches per epochs) for ljspeech



  ### FastSpeech
  energy_embed_kernel_size: 1
  energy_embed_dropout: 0.0
  pitch_embed_kernel_size: 1
  pitch_embed_dropout: 0.0

  # Pitch Predictor
  pitch_predictor_layers: 30
  pitch_predictor_chans: 512
  pitch_predictor_kernel_size: 3
  pitch_aheads: 8
  pitch_attn_layers: 10
  pitch_predictor_dropout_rate : 0.5

  # Duration Predictor
  duration_predictor_layers : 30
  duration_predictor_chans : 512
  duration_predictor_kernel_size : 3
  duration_aheads: 8
  duration_attn_layers: 10
  duration_predictor_dropout_rate : 0.2


  # training related
  transformer_init: 'pytorch' # choices:["pytorch", "xavier_uniform", "xavier_normal", "kaiming_uniform", "kaiming_normal"]
  transformer_warmup_steps: 4000
  transformer_lr: 1.0
  initial_encoder_alpha: 1.0
  initial_decoder_alpha: 1.0
  eprenet_dropout_rate: 0.0
  dprenet_dropout_rate: 0.5
  postnet_dropout_rate: 0.5
  transformer_enc_dropout_rate: 0.1
  transformer_enc_positional_dropout_rate: 0.1
  transformer_enc_attn_dropout_rate: 0.1
  transformer_dec_dropout_rate: 0.1
  transformer_dec_positional_dropout_rate: 0.1
  transformer_dec_attn_dropout_rate: 0.1
  transformer_enc_dec_attn_dropout_rate: 0.1
  use_guided_attn_loss: True
  num_heads_applied_guided_attn: 2
  num_layers_applied_guided_attn: 2
  modules_applied_guided_attn: [ "encoder_decoder" ]
  guided_attn_loss_sigma: 0.4
  guided_attn_loss_lambda: 1.0



  # Diffusion parameters
  timesteps: 4
  dilation_cycle_length: 1
  residual_layers: 20
  residual_channels: 256
  decay_steps: 50000
  keep_bins: 80

  # QKV attention
  qkv_num_tokens: 32
  qkv_heads: 8


speech_prompt:
  idim: 128
  adim: 512
  kernel_size: 9
  padding: 4
  nheads: 8
  num_layers: 6
  ff_units: 2048
  dropout: 0.2

codec:
  dim: 128
  loss_weight: 1

decoder:
  adim: 512
  num_layers: 40
  attn_layers: 10
  nheads: 8
  attn_dropout: 0.2
  wavenet_stack: 3

diff:
  target_sample_hz: 75
  timesteps: 1000
  use_ddim: True
  noise_schedule: 'sigmoid'
  objective: 'v'
  schedule_config:
    start: -3
    end: 3
    tau: 1
  time_difference: 0.
  min_snr_loss_weight: True
  min_snr_gamma: 5
  train_prob_self_cond: 0.9
  rvq_cross_entropy_loss_weight: 0.
  scale: 1.




train:
  # optimization related
  lr: 0.0001
  eos: False #True
  opt: 'noam'
  accum_grad: 1
  grad_clip: 1.0
  weight_decay: 0.999
  patience: 0
  epochs: 5000  # 1,000 epochs * 809 batches / 5 accum_grad : 161,800 iters
  save_interval_epoch: 10
  GTA : False
  # other
  ngpu: 1       # number of gpus ("0" uses cpu, otherwise use gpu)
  nj: 4        # number of parallel jobs
  dumpdir: '' # directory to dump full features
  verbose: 0    # verbose option (if set > 0, get more log)
  N: 0          # number of minibatches to be used (mainly for debugging). "0" uses all minibatches.
  seed: 1       # random seed number
  resume: ""    # the snapshot path to resume (if set empty, no effect)
  use_phonemes: True
  batch_size : 48
  # other
  save_interval : 2000
  chkpt_dir : './checkpoints'
  log_dir : './logs'
  summary_interval : 200
  validation_step : 1000
  tts_max_mel_len : 870              # if you have a couple of extremely long spectrograms you might want to use this
  tts_bin_lengths : True              # bins the spectrogram lengths before sampling in data loader - speeds up training